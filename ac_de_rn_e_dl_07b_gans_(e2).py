# -*- coding: utf-8 -*-
"""AC de RN e DL - 07b - GANs (E2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T1nb4Ki2lqobSRwhxl_J2JtbEuaUMdrN

# GANs_Exemplo2 (AC)

Seu grupo deverá explicar detalhadamente no próprio Colab todos os detalhes do código abaixo.

As explicações serão apresentadas na aula do dia 02/06/2025 e as perguntas feitas sobre o código e a execução deveão ser respondidas. Não apresentar de forma completa o código, em detalhes, e/ou responder à alguma das perguntas feitas, levará à descontos na nota da AC.

GRUPO 1:
Rafael
Daniel
Ivo
Pedro
André
Gustavo
Lucca
Bernardo
João

### **Importando bibliotecas**

Importação:

NumPy — criar e manipular arrays e números aleatórios.

Keras — construir e treinar redes neurais (com camadas como convolução, ativação, normalização e dropout).

Fashion-MNIST — conjunto de dados de imagens de roupas para treinar e testar modelos.

Inicializadores e otimizadores — definir como os pesos começam e como eles são ajustados.

Matplotlib — desenhar gráficos e visualizar resultados.

Funções matemáticas — como raiz quadrada.

Objetivo: trabalhar com redes neurais em Keras, usando imagens, inicialização de pesos e otimização, além de ferramentas para visualização e operações numéricas.
"""

# Importação de múltiplas bibliotecas para construção da GAN
# Componentes para manipulação numérica (NumPy), redes neurais (Keras), matemáticos (math) e visualização (matplotlib)
from numpy import zeros, ones, expand_dims, asarray
from numpy.random import randn, randint
from keras.datasets import fashion_mnist
from keras.optimizers import Adam
from keras.models import Model, load_model
from keras.layers import Input, Dense, Reshape, Flatten
from keras.layers import Conv2D, Conv2DTranspose, Concatenate
from keras.layers import LeakyReLU, Dropout, Embedding
from keras.layers import BatchNormalization, Activation
from keras import initializers
from keras.initializers import RandomNormal
from keras.optimizers import Adam, RMSprop, SGD
from matplotlib import pyplot
import numpy as np
from math import sqrt

"""### **Carregando conjuntos de dados**

Esse código carrega as imagens de treino do Fashion-MNIST, normaliza os valores dos pixels para o intervalo de -1 a 1, adiciona uma dimensão de canal para compatibilidade com redes convolucionais e imprime o formato final das imagens.
"""

# Carrega o Fashion MNIST - somente as imagens de treino (rótulos descartados)
(X_train, _), (_, _) = fashion_mnist.load_data()

#  Normalização: converte os valores dos pixels para float32 e normaliza os dados para ficarem entre -1 e 1
# A divisão por 127.5 e subtração de 1 transforma os valores de [0, 255] para o intervalo [-1, 1]
# Isso é comum quando usamos certos modelos, como GANs, que se beneficiam de dados centralizados ao redor de 0
X_train = X_train.astype(np.float32) / 127.5 - 1

# Adiciona uma dimensão extra ao final de cada imagem (eixo 3) para representar o canal de cinza para uso em CNNs
# np.expand_dims(..., axis=3) transforma isso em (n amostras, 28, 28, 1), onde 1 é o canal (por exemplo, 1 canal para imagens em tons de cinza)
# Isso é necessário para trabalhar com redes convolucionais que esperam entrada com canais explícitos (como no TensorFlow/Keras)
X_train = np.expand_dims(X_train, axis=3)

# Exibe dimensões finais do dataset de treino
print(X_train.shape)

"""### **Criando funções de base**

A seguir, as quatro funções servem como auxiliares, isto é, como base para o desenvolvimento e treinamento da GAN.
"""

# Função que cria o conjunto de vetores aleatórios (pontos latentes) que servem como entrada para o gerador em uma GAN
def generate_latent_points(latent_dim, n_samples):
    # Gera um vetor de números aleatórios da distribuição normal padrão (média 0, desvio padrão 1), com comprimento latent_dim * n_samples
    x_input = randn(latent_dim * n_samples)
    # Reshape para formar n_samples vetores, cada um com latent_dim dimensões. Esse será o input do gerador
    # Ou seja o z_input serão os valores de x_input transformados em matriz
    z_input = x_input.reshape(n_samples, latent_dim)
    return z_input

# Função que sorteia amostras reais do dataset para treinar o discriminador, selecionando como reais
# Seleciona amostras reais aleatórias e gera rótulos "verdadeiros" (1)
def generate_real_samples(X_train, n_samples):
    #Seleciona aleatoriamente n_samples índices das imagens reais
    ix = randint(0, X_train.shape[0], n_samples)
    #Seleciona as imagens reais com base nos índices
    X = X_train[ix]
    # Cria um vetor de rótulos com valor 1 (representando "real") com o mesmo número de amostras. Isso será usado como rótulo para o discriminador
    y = ones((n_samples, 1))
    return X, y

# Função que gera imagens falsas usando o gerador e as marca como falsas para treinar o discriminador
# Gera amostras falsas usando o gerador e rótulos falsos (0)
def generate_fake_samples(generator, latent_dim, n_samples):
    # Gera vetores no espaço latente como entrada para o gerador.
    z_input = generate_latent_points(latent_dim, n_samples)
    # Usa o modelo gerador para criar imagens falsas a partir dos vetores latentes.
    images = generator.predict(z_input)
    # Cria um vetor de rótulos com valor 0 (representando "falso") com o mesmo número de amostras.
    y = zeros((n_samples, 1))
    return images, y

# Avalia o desempenho do gerador durante o treinamento: gera 100 imagens de exemplo, reverte a normalização para [0,1] e exibe as imagens em subplots 10x10
# Para cada imagem gerada (100 imagens):
# Cria uma subimagem (subplot) em uma grade 10x10.
# Desativa os eixos.
# Exibe a imagem em tons de cinza invertidos (gray_r).
def summarize_performance(step, g_model, latent_dim, n_samples=100):
    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)
    X = (X + 1) / 2.0 # Converte de [-1,1] para [0,1]
    for i in range(100):
        pyplot.subplot(10, 10, 1 + i)
        pyplot.axis('off')
        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')
    # Cria o nome do arquivo para salvar o modelo com base na etapa atual (step), preenchendo com zeros à esquerda (ex: model_0005.h5).
    filename2 = 'model_%04d.h5' % (step+1)
    g_model.save(filename2) # Salva somente o gerador
    print('>Saved: %s' % (filename2))

"""### **Definições da Arquitetura da GAN**"""

# Função que define a arquitetura do discriminador, que recebe uma imagem de 28x28 pixels com 1 canal (escala de cinza, como no Fashion-MNIST) e tenta classificar se é real ou falsa
# Define o discriminador como rede MLP (não convolucional): usa camadas Densas com vazamento de 20% nos neurônios (LeakyReLU), Dropout de 30% para reduzir overfitting e saída sigmoid para classificação binária [real/falso]
def define_discriminator(in_shape=(28, 28, 1)):
    #Cria um inicializador de pesos usando distribuição normal com desvio padrão de 0.02 — comum em redes adversariais para estabilizar o treinamento
    init = RandomNormal(stddev=0.02)
    #Define o tensor de entrada da rede, que receberá uma imagem com o formato (28, 28, 1)
    in_image = Input(shape=in_shape)
    #Achata a imagem (transforma de 28×28×1 para um vetor 1D de tamanho 784) para alimentar camadas densas
    fe = Flatten()(in_image)
    # Adiciona uma camada totalmente conectada (densa) com 1024 neurônios
    fe = Dense(1024)(fe)
    # Aplica a função de ativação Leaky ReLU, que permite pequenos valores negativos (com inclinação 0.2)
    fe = LeakyReLU(alpha=0.2)(fe)
    # Aplica dropout de 30% para evitar overfitting (desativa 30% dos neurônios aleatoriamente durante o treino)
    fe = Dropout(0.3)(fe)
    #Outra camada densa, agora com 512 neurônios.
    fe = Dense(512)(fe)
    # Ativação Leaky ReLU + Dropout novamente, com os mesmos propósitos descritos acima
    fe = LeakyReLU(alpha=0.2)(fe)
    fe = Dropout(0.3)(fe)
    #Mais uma camada densa com 256 neurônios, ativação Leaky ReLU e Dropout
    fe = Dense(256)(fe)
    fe = LeakyReLU(alpha=0.2)(fe)
    fe = Dropout(0.3)(fe)
    #Camada de saída com 1 neurônio e ativação sigmoide, que retorna um valor entre 0 e 1 — interpretado como a probabilidade de a imagem ser real
    out = Dense(1, activation='sigmoid')(fe)
    #Cria o modelo Keras funcional, conectando a entrada (in_image) à saída (out)
    model = Model(in_image, out)
    #Compila o modelo
    #loss='binary_crossentropy': porque é um problema binário (imagem real = 1, falsa = 0)
    #metrics=['accuracy']: mede a acurácia durante o treinamento
    model.compile(loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Função que define a arquitetura do gerador, que recebe um vetor aleatório e produz uma imagem falsa
# Define o gerador que mapeia espaço latente para imagens 28x28
def define_generator(latent_dim):
    # Cria um inicializador de pesos usando distribuição normal com desvio padrão de 0.02 — comum em redes adversariais para estabilizar o treinamento
    init = RandomNormal(stddev=0.02)
    # Define a entrada da rede: vetor latente com tamanho igual a latent_dim
    in_lat = Input(shape=(latent_dim,))
    # Primeira camada densa: expande o vetor latente para 256 neurônios
    gen = Dense(256, kernel_initializer=init)(in_lat)
    # Aplica ativação Leaky ReLU para permitir pequenos valores negativos e melhorar o fluxo de gradientes
    gen = LeakyReLU(alpha=0.2)(gen)
    # Segunda camada densa: expande para 512 neurônios
    gen = Dense(512, kernel_initializer=init)(gen)
    gen = LeakyReLU(alpha=0.2)(gen)
    # Terceira camada densa: expande para 1024 neurônios
    gen = Dense(1024, kernel_initializer=init)(gen)
    gen = LeakyReLU(alpha=0.2)(gen)
    # Camada final densa: produz 28x28x1 = 784 valores, que representam os pixels da imagem gerada
    gen = Dense(28 * 28 * 1, kernel_initializer=init)(gen)
    # Aplica a função de ativação tanh para restringir os valores da imagem gerada para o intervalo [-1,1]
    out_layer = Activation('tanh')(gen)
    # Redimensiona o vetor de saída para o formato (28, 28, 1)
    out_layer = Reshape((28, 28, 1))(gen)
    # Cria o modelo funcional Keras conectando a entrada latente à imagem gerada
    model = Model(in_lat, out_layer)
    return model

# Função que combina gerador e discriminador em um único modelo para treinar o gerador a enganar o discriminador
# Conecta gerador ao discriminador CONGELADO - isto é, no modelo combinado, o discriminador não é atualizado
def define_gan(g_model, d_model):
    # Congela os pesos do discriminador para que eles não sejam atualizados durante o treino do gerador
    d_model.trainable = False
    # Conecta a saída do gerador como entrada do discriminador
    gan_output = d_model(g_model.output)
    model = Model(g_model.input, gan_output)
    # Uso da acurácia: mede a acurácia da GAN durante o treinamento
    # Binary crossentropy: discriminador é binário (real ou falso)
    model.compile(loss='binary_crossentropy', metrics=['accuracy'])
    return model

"""### **Instanciando o modelo**

O trecho abaixo inicializa os três principais componentes de uma GAN: o discriminador (classificador binário), o gerador (gerador de imagens) e o modelo combinado que os conecta para o treinamento do gerador.
"""

# Cria discriminador (rede de classificação)
# define_discriminator() é instanciada para criar o modelo discriminador, que será usado para classificar imagens como reais ou falsas -  resultado é armazenado na variável discriminator
discriminator = define_discriminator()

# Cria gerador com vetor latente de 100 dimensões
# define_generator() é chamada com o argumento 100, definindo a dimensão do espaço latente (vetor de entrada aleatório) usado para gerar imagens falsa - modelo gerador é criado e armazenado na variável generator
generator = define_generator(100)

# Conecta gerador ao discriminador
# define_gan() é chamada para combinar o gerador e o discriminador em um único modelo GAN. Esse modelo é usado para treinar o gerador de forma que ele tente enganar o discriminador - modelo GAN é armazenado na variável gan_model
gan_model = define_gan(generator, discriminator)

"""### **Função train()**

A função train executa o treinamento da GAN. Ela calcula quantos batches existem por época e quantas iterações são necessárias para o treinamento completo.

Em cada iteração, ela primeiro gera amostras reais do conjunto de treino e treina o discriminador para classificá-las corretamente, depois gera amostras falsas usando o gerador e treina o discriminador para classificá-las como falsas.

Em seguida, treina o gerador, via o modelo GAN, para tentar enganar o discriminador, incentivando o gerador a produzir imagens mais realistas. A função exibe a cada iteração as métricas de perda e precisão de cada etapa e, periodicamente, salva o modelo do gerador e exibe imagens geradas para acompanhar o progresso.

Ao final, todo o ciclo de treinamento é realizado, permitindo que o gerador e o discriminador aprendam juntos.

**Resumo dos passos | Processo por iteração:**

1. Treina discriminador com lote de imagens REAIS (rótulo 1)
2. Treina discriminador com lote de imagens FALSAS (rótulo 0)
3. Treina gerador via modelo GAN (tentando "enganar" discriminador com rótulo 1)
4. Periodicamente salva o gerador e gera amostras visuais
"""

def train(g_model, d_model, gan_model, X_train, latent_dim, n_epochs=100, n_batch=64):
    bat_per_epo = int(X_train.shape[0] / n_batch) # Calcula quantos batches por época
    n_steps = bat_per_epo * n_epochs # # Total de iterações
    # Treina a GAN repetindo o treino do discriminador e do gerador em várias iterações, salvando modelos e imagens periodicamente.
    for i in range(n_steps):
        # Fase 1: Treino discriminador - amostras reais
        X_real, y_real = generate_real_samples(X_train, n_batch)
        d_loss_r, d_acc_r = d_model.train_on_batch(X_real, y_real)

        # Fase 2: Treino discriminador - amostras falsas
        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_batch)
        d_loss_f, d_acc_f = d_model.train_on_batch(X_fake, y_fake)

        # Fase 3: Treino gerador (via GAN)
        z_input = generate_latent_points(latent_dim, n_batch)
        y_gan = ones((n_batch, 1))
        g_loss, g_acc = gan_model.train_on_batch(z_input, y_gan)

        # Print com informações de progresso por iteração
        print('>%d, dr[%.3f,%.3f], df[%.3f,%.3f], g[%.3f,%.3f]' % (i+1, d_loss_r,d_acc_r, d_loss_f,d_acc_f, g_loss,g_acc))

        # Avaliação ao final de cada época
        if (i+1) % (bat_per_epo * 1) == 0: # Verifica se chegou ao final de uma época
            summarize_performance(i, g_model, latent_dim)

# Chama a função de treino definida, passando o gerador, o discriminador, o modelo GAN, o conjunto de dados de treino (X_train), a dimensão do espaço latente (100), epochs (5) e batch size (512) - iniciando o treinamento da GAN com esses parâmetros
train(generator, discriminator, gan_model, X_train, latent_dim=100, n_epochs=5, n_batch=512)