# -*- coding: utf-8 -*-
"""AP2_Projeto_Deep_Learning - Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A7bnOwanLHfvRgDVE_h5_AYnI-IaQQMs
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, concatenate, Dropout, multiply
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2 # Importar regularizador L2
from tensorflow.keras.callbacks import EarlyStopping # Importar EarlyStopping
import matplotlib.pyplot as plt

# --- 1. Carregamento e Pré-processamento dos Dados ---
print("Carregando os dados...")
#Estas colunas estão no dataset de ratings
ratings_cols = ['UserID', 'MovieID', 'Rating', 'Timestamp']
#Estas colunas estão no dataset de users
users_cols = ['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']
#Estas colunas estão no dataset de movies
movies_cols = ['MovieID', 'Title', 'Genres']

#Aqui carrego os 3 datasets
ratings = pd.read_csv('ratings.dat', sep='::', engine='python', header=None, names=ratings_cols, encoding='latin-1')
users = pd.read_csv('users.dat', sep='::', engine='python', header=None, names=users_cols, encoding='latin-1')
movies = pd.read_csv('movies.dat', sep='::', engine='python', header=None, names=movies_cols, encoding='latin-1')

print("Dados carregados.")

#Aqui eu faço o merge dos datasets
data = pd.merge(ratings, users[['UserID', 'Gender']], on='UserID')
data = pd.merge(data, movies[['MovieID', 'Title', 'Genres']], on='MovieID')

print("\nDados mesclados. Primeiras linhas:")
print(data.head())

#Transformo em um problema binario
data['Liked'] = (data['Rating'] >= 4).astype(int)
print("\nTransformando ratings em problema binário ('Liked'):")
print(data['Liked'])
print(data['Liked'].value_counts())



#A principio não preciso destas 3 linhas pois ja são numéricas
#user_enc = LabelEncoder()
#data['UserID_encoded'] = user_enc.fit_transform(data['UserID'])
#n_users = data['UserID_encoded'].nunique()

#Não preciso desta 3 linhas pois ja são numericas
#movie_enc = LabelEncoder()
#data['MovieID_encoded'] = movie_enc.fit_transform(data['MovieID'])
#n_movies = data['MovieID_encoded'].nunique()

gender_enc = LabelEncoder()
data['Gender_encoded'] = gender_enc.fit_transform(data['Gender'])
n_genders = data['Gender_encoded'].nunique()

print("\nFeatures codificadas.")
print(f"Número de classes de gênero: {n_genders}")
print("\nDados com colunas codificadas:")
print(data.head())

# --- 2. Preparar Dados para o Modelo ---
X = data[['UserID', 'MovieID', 'Gender_encoded']].values
y = data['Liked'].values

#Aqui faz o train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nDados divididos em treino e teste.")
print(f"Tamanho do conjunto de treino (X_train): {X_train.shape}")
print(f"Tamanho do conjunto de teste (X_test): {X_test.shape}")

#Separa os dados de treino em 3 colunas
train_user_ids = X_train[:, 0]
train_movie_ids = X_train[:, 1]
train_gender_ids = X_train[:, 2]

#Sepera os dados de teste em 3 colunas
test_user_ids = X_test[:, 0]
test_movie_ids = X_test[:, 1]
test_gender_ids = X_test[:, 2]

# --- 3. Construir o Modelo NCF com Regularização L2 ---
print("\nConstruindo o modelo NCF com regularização L2...")

embedding_dim_user_movie = 50
embedding_dim_gender = 10
l2_reg_strength = 0.001 # Fator de regularização L2. Pode ser ajustado (ex: 0.01, 0.0001)

# Entradas do modelo
user_id_input = Input(shape=(1,), name='user_id_input')
movie_id_input = Input(shape=(1,), name='movie_id_input')
gender_input = Input(shape=(1,), name='gender_input')

# --- Parte GMF (Generalized Matrix Factorization) ---
user_embedding_gmf = Embedding(input_dim=data['UserID'].max()+1, output_dim=embedding_dim_user_movie,
                               embeddings_regularizer=l2(l2_reg_strength), # Adicionando L2
                               name='user_embedding_gmf')(user_id_input)
user_flatten_gmf = Flatten(name='user_flatten_gmf')(user_embedding_gmf)

movie_embedding_gmf = Embedding(input_dim=data['MovieID'].max()+1, output_dim=embedding_dim_user_movie,
                                embeddings_regularizer=l2(l2_reg_strength), # Adicionando L2
                                name='movie_embedding_gmf')(movie_id_input)
movie_flatten_gmf = Flatten(name='movie_flatten_gmf')(movie_embedding_gmf)

gmf_output = multiply([user_flatten_gmf, movie_flatten_gmf], name='gmf_output')

# --- Parte MLP (Multi-Layer Perceptron) ---
user_embedding_mlp = Embedding(input_dim=data['UserID'].max()+1, output_dim=embedding_dim_user_movie,
                               embeddings_regularizer=l2(l2_reg_strength), # Adicionando L2
                               name='user_embedding_mlp')(user_id_input)
user_flatten_mlp = Flatten(name='user_flatten_mlp')(user_embedding_mlp)

movie_embedding_mlp = Embedding(input_dim=data['MovieID'].max()+1, output_dim=embedding_dim_user_movie,
                                embeddings_regularizer=l2(l2_reg_strength), # Adicionando L2
                                name='movie_embedding_mlp')(movie_id_input)
movie_flatten_mlp = Flatten(name='movie_flatten_mlp')(movie_embedding_mlp)

gender_embedding_mlp = Embedding(input_dim=n_genders, output_dim=embedding_dim_gender,
                                 embeddings_regularizer=l2(l2_reg_strength), # Adicionando L2
                                 name='gender_embedding_mlp')(gender_input)
gender_flatten_mlp = Flatten(name='gender_flatten_mlp')(gender_embedding_mlp)

mlp_concatenate = concatenate([user_flatten_mlp, movie_flatten_mlp, gender_flatten_mlp], name='mlp_concatenate')

mlp_dense1 = Dense(64, activation='relu', kernel_regularizer=l2(l2_reg_strength), name='mlp_dense1')(mlp_concatenate) # Adicionando L2
mlp_dropout1 = Dropout(0.3, name='mlp_dropout1')(mlp_dense1)
mlp_dense2 = Dense(32, activation='relu', kernel_regularizer=l2(l2_reg_strength), name='mlp_dense2')(mlp_dropout1) # Adicionando L2
mlp_dropout2 = Dropout(0.3, name='mlp_dropout2')(mlp_dense2)
mlp_output = mlp_dropout2

# --- Combinação Final (NeuMF) ---
combine_gmf_mlp = concatenate([gmf_output, mlp_output], name='combine_gmf_mlp')

# Camada de Saída (pode-se adicionar L2 aqui também, mas é menos comum para a camada de saída direta)
output_layer = Dense(1, activation='sigmoid', name='output_layer')(combine_gmf_mlp)

model = Model(inputs=[user_id_input, movie_id_input, gender_input], outputs=output_layer)

model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

print("\nModelo construído e compilado.")
model.summary()

# --- 4. Treinar o Modelo com Early Stopping ---
print("\nTreinando o modelo com Early Stopping e Regularização L2...")

train_inputs = [train_user_ids, train_movie_ids, train_gender_ids]

# Definir o callback EarlyStopping
# Monitora 'val_loss'. 'patience' é o número de épocas sem melhora após o qual o treino para.
# 'restore_best_weights=True' garante que o modelo retorne com os pesos da melhor época.
early_stopping_cb = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)

history = model.fit(train_inputs, y_train,
                    epochs=5, # Aumentar o número de épocas; EarlyStopping vai parar antes se necessário
                    batch_size=10,
                    validation_split=0.2,
                    verbose=1,
                    callbacks=[early_stopping_cb]) # Adicionar o callback aqui

print("\nTreinamento finalizado.")
if early_stopping_cb.stopped_epoch > 0:
    print(f"Treinamento interrompido por EarlyStopping na época: {early_stopping_cb.stopped_epoch + 1}")
    print(f"Melhor loss de validação ({early_stopping_cb.monitor}): {early_stopping_cb.best:.4f}")

# --- 5. Avaliar o Modelo ---
print("\nAvaliando o modelo no conjunto de teste...")

test_inputs = [test_user_ids, test_movie_ids, test_gender_ids]
loss, accuracy = model.evaluate(test_inputs, y_test, verbose=0)

print(f"Perda no teste: {loss:.4f}")
print(f"Acurácia no teste: {accuracy:.4f}")

# --- 6. Visualizar Histórico de Treinamento ---
print("\nGerando gráfico de histórico de treinamento...")
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Loss de Treinamento')
if 'val_loss' in history.history:
    plt.plot(history.history['val_loss'], label='Loss de Validação')
plt.title('Loss do Modelo')
plt.xlabel('Época')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')
if 'val_accuracy' in history.history:
    plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')
plt.title('Acurácia do Modelo')
plt.xlabel('Época')
plt.ylabel('Acurácia')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

import random
sample_index = random.randint(0, len(test_user_ids) - 1)

sample_user_id = test_user_ids[sample_index]
sample_movie_id = test_movie_ids[sample_index]
sample_gender_id = test_gender_ids[sample_index]
actual_liked_status = y_test[sample_index]

user_input_pred = np.array([sample_user_id])
movie_input_pred = np.array([sample_movie_id])
gender_input_pred = np.array([sample_gender_id])
prediction_inputs = [user_input_pred, movie_input_pred, gender_input_pred]

predicted_probability = model.predict(prediction_inputs)[0][0]
predicted_class = (predicted_probability > 0.5).astype(int)

original_gender = gender_enc.inverse_transform([sample_gender_id])[0]
movie_info = movies[movies['MovieID'] == sample_movie_id].iloc[0]
original_movie_title = movie_info['Title']
original_movie_genres = movie_info['Genres']

print(f"\n--- Predição para Amostra ---")
print(f"UserID: {sample_user_id}")
print(f"Gênero do Usuário: {original_gender}")
print(f"MovieID: {sample_movie_id}")
print(f"Título do Filme: {original_movie_title}")
print(f"Gêneros do Filme: {original_movie_genres}")
print(f"Probabilidade Prevista de 'Gostar': {predicted_probability:.4f}")
print(f"Classe Prevista: {predicted_class}")
print(f"Valor Real de 'Gostar': {actual_liked_status}")